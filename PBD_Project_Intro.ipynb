{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linnbogren/big_data_project/blob/main/PBD_Project_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IZmANDZlh9fu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921461d7-51f6-49c3-8aa9-1d4f8248b6c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive - Only if you are working with Colab, discard otherwise\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_folder_path = '/content/drive/My Drive/KTH/utbyte/Big Data/project_big_data/Project_Data'\n",
        "features_path = data_folder_path + '/Features'\n",
        "audio_path = data_folder_path + '/Audio'\n",
        "video_frames_path = data_folder_path + '/Video_Frames'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2kTxSZ6ziCQI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8mTvBaGi5lE"
      },
      "source": [
        "# **Visual Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ro8Nw95gjMwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8644ffd3-c646-4ee8-d240-3e7440db77e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cdu-ps_visual.pkl', 'chega-be_visual.pkl', 'ad-livre_visual.pkl', 'ad-cdu_visual.pkl', 'ad-be_visual.pkl', 'chega-cdu_visual.pkl', 'be-ps_visual.pkl', 'ad-il_visual.pkl', 'cdu-be_visual.pkl', 'ad-pan_visual.pkl', 'ad-ps_visual.pkl', 'chega-il_visual.pkl', 'ad-chega_visual.pkl', 'pan-ps_visual.pkl', 'pan-chega_visual.pkl', 'il-ps_visual.pkl', 'livre-ps_visual.pkl', 'livre-chega_visual.pkl', 'pan-cdu_visual.pkl', 'il-cdu_visual.pkl', 'il-be_visual.pkl', 'chega-ps_visual.pkl', 'livre-be_visual.pkl', 'pan-livre_visual.pkl', 'pan-il_visual.pkl', 'livre-il_visual.pkl', 'livre-cdu_visual.pkl', 'pan-be_visual.pkl']\n"
          ]
        }
      ],
      "source": [
        "#List all Pickle (.pkl) files\n",
        "pklfiles = [f for f in os.listdir(features_path) if os.path.isfile(os.path.join(features_path, f)) and f.endswith('_visual.pkl')]\n",
        "print(pklfiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZyQlGI5jom8"
      },
      "outputs": [],
      "source": [
        "# Load one\n",
        "video = 'ad-ps'\n",
        "data = pd.read_pickle(os.path.join(features_path, video + '_visual.pkl'))\n",
        "\n",
        "# Print first lines\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHJurZfQkNjZ"
      },
      "outputs": [],
      "source": [
        "#Access one frame\n",
        "data.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmVyOlvokelb"
      },
      "outputs": [],
      "source": [
        "#Lets visualize some features in the images - Detections\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "frame = 2012\n",
        "\n",
        "frame_id = data.iloc[frame]['filename']\n",
        "print(frame_id)\n",
        "\n",
        "img = Image.open(os.path.join(video_frames_path, video, frame_id))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "ax.imshow(img)\n",
        "\n",
        "print(data.iloc[frame]['detections'])\n",
        "\n",
        "for bbox in data.iloc[frame]['detections']:\n",
        "\n",
        "    # Create a rectangle patch\n",
        "    rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor='r', facecolor='none')\n",
        "\n",
        "    # Add patch to the image\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    ax.text(bbox[0], bbox[1], f'{bbox[4]} ({100*bbox[5]:.1f}%)',\n",
        "            verticalalignment='top',\n",
        "            color='r')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRy4gobXl4Lk"
      },
      "outputs": [],
      "source": [
        "# Poses\n",
        "poses = np.array(data.iloc[frame]['poses'])\n",
        "\n",
        "print(poses.shape) # 1 pose, 33 keypoints, 5 values [x,y,z,visibility,presence]\n",
        "\n",
        "#With visibility and presence thresholds\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "ax.imshow(img)\n",
        "\n",
        "width, height = img.size\n",
        "for pose in np.array(data.iloc[frame]['poses']):\n",
        "\n",
        "    # convert normalized landmark to pixel position\n",
        "    x = np.floor(pose[:,0] * width)\n",
        "    y = np.floor(pose[:,1] * height)\n",
        "\n",
        "    for i in range(pose.shape[0]):\n",
        "        if pose[i,3]>.5 and pose[i,4]>.5: #visibility and presence thresholds\n",
        "            plt.scatter(x[i], y[i], color='w')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW9nptclqWVS"
      },
      "outputs": [],
      "source": [
        "# Facial emotion recognition\n",
        "\n",
        "fers = data.iloc[frame]['fer']\n",
        "\n",
        "print(fers[0].keys())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_2xP6mFqz5u"
      },
      "outputs": [],
      "source": [
        "print(fers[0]['location'])\n",
        "print(fers[0]['embedding'])\n",
        "\n",
        "print(fers[0]['emotion'])\n",
        "\n",
        "print(fers[0]['logits'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "144bGBIVnOH3"
      },
      "outputs": [],
      "source": [
        "#Visualize emotions and detected faces\n",
        "idx_to_class={0: 'Anger', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happiness', 5: 'Neutral', 6: 'Sadness', 7: 'Surprise'}\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "ax.imshow(img)\n",
        "\n",
        "width, height = img.size\n",
        "\n",
        "fers = data.iloc[frame]['fer']\n",
        "print(fers)\n",
        "\n",
        "for fer in fers:\n",
        "\n",
        "    x = fer['location'][0]\n",
        "    y = fer['location'][2]\n",
        "    width = fer['location'][1] - fer['location'][0]\n",
        "    height = fer['location'][3] - fer['location'][2]\n",
        "\n",
        "    print(fer['emotion'])\n",
        "\n",
        "    # Create a rectangle patch\n",
        "    rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='g', facecolor='none')\n",
        "\n",
        "    # Add patch to the image\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    ax.text(x, y, fer['emotion'],\n",
        "            verticalalignment='top',\n",
        "            color='g')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqhuye1-oNgr"
      },
      "source": [
        "# **Audio & Speech**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi2wfeZ-oVz6"
      },
      "outputs": [],
      "source": [
        "#List all Pickle (.pkl) files\n",
        "\n",
        "pklfiles = [f for f in os.listdir(features_path) if os.path.isfile(os.path.join(features_path, f)) and f.endswith('_audio.pkl')]\n",
        "print(pklfiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2swGcu5UohG5"
      },
      "outputs": [],
      "source": [
        "# Load one\n",
        "video = 'ad-ps'\n",
        "data_audio = pd.read_pickle(os.path.join(features_path, video + '_audio.pkl'))\n",
        "\n",
        "# Print first lines\n",
        "data_audio.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKab57CxpllB"
      },
      "outputs": [],
      "source": [
        "print(data_audio.keys()) #Check feature names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYcuE9W1rWJW"
      },
      "outputs": [],
      "source": [
        "#Align with the video frame (second 1712)\n",
        "print(data_audio['time stamp'][19:25])\n",
        "print(data_audio['duration'][19:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heNeywURslSj"
      },
      "outputs": [],
      "source": [
        "print(data_audio.iloc[19])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2SOWxEMtjdb"
      },
      "outputs": [],
      "source": [
        "#Lets listen\n",
        "from scipy.io import wavfile\n",
        "from IPython.display import Audio\n",
        "\n",
        "samplerate, audio = wavfile.read(os.path.join(audio_path, video + '.wav'))\n",
        "\n",
        "sample = audio[int(data_audio.iloc[19]['time stamp']*samplerate):int(data_audio.iloc[19]['time stamp']+data_audio.iloc[19]['duration'])*samplerate,0]\n",
        "\n",
        "display(Audio(sample,rate=samplerate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOCBjjs5u18_"
      },
      "outputs": [],
      "source": [
        "#List all Pickle (.pkl) files\n",
        "\n",
        "pklfiles = [f for f in os.listdir(features_path) if os.path.isfile(os.path.join(features_path, f)) and f.endswith('_speech.pkl')]\n",
        "print(pklfiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cV9emIbu-ye"
      },
      "outputs": [],
      "source": [
        "# Load one\n",
        "video = 'ad-ps'\n",
        "data_speech = pd.read_pickle(os.path.join(features_path, video + '_speech.pkl'))\n",
        "\n",
        "# Print first lines\n",
        "data_speech.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyRzyGKQvJ6S"
      },
      "outputs": [],
      "source": [
        "#Verify the transcritp\n",
        "transcript = data_speech.iloc[19]['transcript']\n",
        "print(transcript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJB9jHaOwNvM"
      },
      "source": [
        "# **Text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYbQ8ZnRyqVe"
      },
      "outputs": [],
      "source": [
        "#Load the single file\n",
        "# Load one\n",
        "data_dictionary = pd.read_pickle(os.path.join(features_path, 'dictionary_text.pkl'))\n",
        "\n",
        "# Print first lines\n",
        "data_dictionary.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVnbaG9cy1nq"
      },
      "outputs": [],
      "source": [
        "#How to explore the dictionary and the transcripts? - Try using Bag-of-Words\n",
        "#Cool demo at https://colab.research.google.com/github/littlecolumns/ds4j-notebooks/blob/master/text-analysis/notebooks/Counting%20words%20with%20scikit-learn's%20CountVectorizer.ipynb\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [transcript]\n",
        "\n",
        "vectorizer = CountVectorizer(vocabulary = data_dictionary.index)\n",
        "count_matrix = vectorizer.transform(corpus)\n",
        "bow = vectorizer.get_feature_names_out()\n",
        "count_array = count_matrix.toarray()\n",
        "\n",
        "print(count_array.shape)\n",
        "print(data_dictionary.index.shape)\n",
        "\n",
        "words = np.where(np.squeeze(count_array) != 0)\n",
        "\n",
        "#See words that were found\n",
        "print(bow[words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPwWZ_Hc0Z_9"
      },
      "outputs": [],
      "source": [
        "#For a full video\n",
        "texts = data_speech['transcript']\n",
        "\n",
        "corpus = []\n",
        "\n",
        "for text in texts:\n",
        "  corpus.append(text)\n",
        "\n",
        "count_matrix = vectorizer.transform(corpus)\n",
        "bow = vectorizer.get_feature_names_out()\n",
        "count_array = count_matrix.toarray()\n",
        "\n",
        "print(count_array.shape)\n",
        "print(data_dictionary.index.shape)\n",
        "\n",
        "for i in range(count_array.shape[0]):\n",
        "  words = np.where(np.squeeze(count_array[i,:]) != 0)\n",
        "\n",
        "  print(bow[words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8A1KT7cxu1J"
      },
      "outputs": [],
      "source": [
        "#Load the single file\n",
        "# Load one\n",
        "data_pulsometer = pd.read_pickle(os.path.join(features_path, 'pulsometer_text.pkl'))\n",
        "\n",
        "# Print first lines\n",
        "data_pulsometer.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-ERCLhhyVYw"
      },
      "outputs": [],
      "source": [
        "#Load the single file\n",
        "# Load one\n",
        "data_grades = pd.read_pickle(os.path.join(features_path, 'grades_text.pkl'))\n",
        "\n",
        "# Print first lines\n",
        "data_grades.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}